// @ts-ignore - Deno runtime imports
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
// @ts-ignore - Deno runtime imports
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.43.4'
// @ts-ignore - Deno runtime imports
import { Image } from 'https://deno.land/x/imagescript@1.3.0/mod.ts'

declare const Deno: {
  env: {
    get(key: string): string | undefined;
  };
};

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
}

type OCRMode = 'process_specific' | 'process_next';

interface OCRRequest {
  statementId?: string;
  imageUrl?: string;
  reset_before_extract?: boolean;
  mode?: OCRMode;
}

// ì…ê³ ìˆ˜ëŸ‰ ì—…ë¡œë“œìš© - ê¸ˆì•¡ í•„ë“œ ì œê±°
interface ExtractedItem {
  line_number: number;
  item_name: string;
  specification?: string;
  quantity: number;
  unit_price?: number | null;  // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  amount?: number | null;       // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  tax_amount?: number | null;   // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  po_number?: string;
  remark?: string;
  confidence: 'low' | 'med' | 'high';
}

// ì…ê³ ìˆ˜ëŸ‰ ì—…ë¡œë“œìš© - ê¸ˆì•¡ í•„ë“œ ì œê±°
interface ExtractionResult {
  statement_date?: string;
  vendor_name?: string;
  vendor_name_english?: string;
  total_amount?: number | null;  // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  tax_amount?: number | null;    // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  grand_total?: number | null;   // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œì—ì„œëŠ” null
  items: ExtractedItem[];
  raw_text?: string;
}

type VisionWord = {
  text: string;
  bbox: { x: number; y: number; w: number; h: number };
};

type RowData = {
  id: number;
  text: string;
  words: VisionWord[];
  minX: number;
  maxX: number;
  minY: number;
  maxY: number;
  centerY: number;
};

type InferredPoInfo = {
  inferred_po_number: string;
  inferred_po_source: 'bracket' | 'handwriting_range' | 'margin_range' | 'per_item' | 'global';
  inferred_po_confidence: number;
  inferred_po_group_id?: string;
};

type PreprocessResult = {
  image: Image;
  base64: string;
};

type ImageTile = {
  base64: string;
  offsetX: number;
  offsetY: number;
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  let statementId: string | null = null
  let claimedStatement: any | null = null
  let supabaseUrl = ''
  let supabaseServiceKey = ''
  let currentStage = 'init'

  try {
    supabaseUrl = Deno.env.get('SUPABASE_URL')!
    supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')
    const googleCredentials = Deno.env.get('GOOGLE_VISION_CREDENTIALS')

    if (!openaiApiKey) {
      throw new Error('OPENAI_API_KEY is not set in environment variables')
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey)
    const requestData: OCRRequest = await req.json().catch(() => ({}))
    const mode: OCRMode = requestData.mode || 'process_specific'
    const workerId = crypto.randomUUID()
    statementId = requestData.statementId || null
    let imageUrl = requestData.imageUrl || null

    // ì˜¤ë˜ëœ processing ì •ë¦¬ (ì•ˆì „ì¥ì¹˜)
    currentStage = 'cleanup_stale'
    try {
      await supabase.rpc('mark_stale_transaction_statements_failed', {
        processing_timeout: '15 minutes'
      })
    } catch (_) {
      // ignore cleanup errors
    }

    currentStage = 'claim_statement'
    if (mode === 'process_next') {
      const { data, error } = await supabase.rpc('claim_next_transaction_statement', {
        worker_id: workerId,
        processing_timeout: '15 minutes'
      })
      if (error) throw error
      const claimed = Array.isArray(data) ? data[0] : data
      if (!claimed) {
        return new Response(
          JSON.stringify({ success: true, skipped: true, reason: 'no_queue_or_processing_active' }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        )
      }
      claimedStatement = claimed
      statementId = claimed.id
      imageUrl = claimed.image_url
    } else {
      if (!statementId) {
        throw new Error('statementId is required')
      }
      const { data, error } = await supabase.rpc('claim_transaction_statement', {
        statement_id: statementId,
        worker_id: workerId,
        processing_timeout: '15 minutes'
      })
      if (error) throw error
      const claimed = Array.isArray(data) ? data[0] : data
      if (!claimed) {
        const queueUpdate: Record<string, any> = {
          status: 'queued',
          queued_at: new Date().toISOString()
        }
        if (requestData.reset_before_extract) {
          queueUpdate.reset_before_extract = true
        }
        await supabase
          .from('transaction_statements')
          .update(queueUpdate)
          .in('status', ['pending', 'queued', 'failed'])
          .eq('id', statementId)
        return new Response(
          JSON.stringify({ success: true, queued: true, status: 'queued', statementId }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        )
      }
      claimedStatement = claimed
      statementId = claimed.id
      imageUrl = claimed.image_url || imageUrl
    }

    if (!statementId || !imageUrl) {
      throw new Error('Missing statementId or imageUrl')
    }

    const shouldReset = Boolean(requestData.reset_before_extract) || Boolean(claimedStatement?.reset_before_extract)

    console.log(`Processing transaction statement: ${statementId}`)

    // 0. ì¬ì¶”ì¶œ ì´ˆê¸°í™” (ì‹¤ì…ê³ ì¼ë§Œ ìœ ì§€)
    if (shouldReset) {
      const { data: existingStatement } = await supabase
        .from('transaction_statements')
        .select('extracted_data')
        .eq('id', statementId)
        .single()

      const preservedActualReceivedDate = (existingStatement?.extracted_data as any)?.actual_received_date

      await supabase
        .from('transaction_statement_items')
        .delete()
        .eq('statement_id', statementId)

      await supabase
        .from('transaction_statements')
        .update({
          statement_date: null,
          vendor_name: null,
          total_amount: null,
          tax_amount: null,
          grand_total: null,
          extraction_error: null,
          reset_before_extract: false,
          extracted_data: preservedActualReceivedDate
            ? { actual_received_date: preservedActualReceivedDate }
            : null
        })
        .eq('id', statementId)
    }

    // 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    currentStage = 'download_image'
    const imageBuffer = await downloadImage(imageUrl)
    let visionBase64 = ''
    let tileImages: ImageTile[] = []
    let decodedImage: Image | null = null

    try {
      currentStage = 'decode_preprocess'
      decodedImage = await decodeImageFromBuffer(imageBuffer)
      if (decodedImage) {
        const preprocessed = await preprocessImage(decodedImage)
        if (preprocessed) {
          visionBase64 = preprocessed.base64
          decodedImage = preprocessed.image
        }
        tileImages = await buildImageTiles(decodedImage)
      }
    } catch (_) {
      decodedImage = null
      tileImages = []
    }

    if (!visionBase64) {
      visionBase64 = arrayBufferToBase64(imageBuffer)
    }
    const base64Image = visionBase64

    // 3. Google Vision OCR í˜¸ì¶œ (ì„ íƒì  - credentialsê°€ ì—†ìœ¼ë©´ GPT-4oë§Œ ì‚¬ìš©)
    let visionText = ''
    let visionWords: VisionWord[] = []
    if (googleCredentials) {
      try {
        currentStage = 'google_vision'
        const visionResult = await callGoogleVision(visionBase64, googleCredentials)
        visionText = visionResult.text
        visionWords = visionResult.words

        if (tileImages.length > 0) {
          const tileResults = await Promise.allSettled(
            tileImages.map((tile) => callGoogleVision(tile.base64, googleCredentials))
          )
          tileResults.forEach((result, index) => {
            if (result.status !== 'fulfilled') return
            const tile = tileImages[index]
            if (result.value.text) {
              visionText = [visionText, result.value.text].filter(Boolean).join('\n')
            }
            if (result.value.words.length > 0) {
              visionWords = visionWords.concat(
                offsetVisionWords(result.value.words, tile.offsetX, tile.offsetY)
              )
            }
          })
        }
      } catch (e) {
        console.warn('Google Vision failed, using GPT-4o only:', e)
      }
    }

    // 4. GPT-4o ë¹„ì „ìœ¼ë¡œ êµ¬ì¡°í™” ì¶”ì¶œ
    currentStage = 'gpt_extract'
    let poScope: 'single' | 'multi' | null = null
    if (claimedStatement?.po_scope) {
      poScope = claimedStatement.po_scope
    } else {
      const { data: scopeRow } = await supabase
        .from('transaction_statements')
        .select('po_scope')
        .eq('id', statementId)
        .single()
      poScope = (scopeRow as any)?.po_scope || null
    }
    const extractionResult = await extractWithGPT4o(
      base64Image,
      visionText,
      openaiApiKey,
      poScope
    )

    // 5. ìˆ«ì íŒ¨í„´ ì „ìš© 2ì°¨ ì¶”ì¶œ (ì €ì‹ ë¢°/ëˆ„ë½ì—ë§Œ)
    let extraOrderNumbers: string[] = []
    if (shouldRetryOrderNumberPass(extractionResult.items)) {
      try {
        currentStage = 'order_numbers_retry'
        extraOrderNumbers = await extractOrderNumbersWithGPT4o(
          base64Image,
          tileImages.map((tile) => tile.base64),
          openaiApiKey
        )
      } catch (_) {
        extraOrderNumbers = []
      }
    }

    // 6. ë°œì£¼/ìˆ˜ì£¼ë²ˆí˜¸ íŒ¨í„´ ì •ê·œí™” (OCR í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ë¹ˆ ì¹¸ì— ì íŒ ë²ˆí˜¸ë„ ì°¾ìŒ)
    let normalizedItems = normalizePoNumbers(
      extractionResult.items,
      visionText,
      extraOrderNumbers
    )

    // 6-1. ì†ê¸€ì”¨ ê´„í˜¸/ì—°ê²°ì„  ê¸°ë°˜ PO ë§¤í•‘ (í’ˆëª©ë³„ ë³´ê°•)
    let bracketMappings: PoMapping[] = []
    try {
      bracketMappings = await extractPoMappingsWithGPT4o(
        base64Image,
        normalizedItems,
        openaiApiKey
      )
      if (bracketMappings.length > 0) {
        normalizedItems = applyPoMappings(normalizedItems, bracketMappings)
      }
    } catch (e) {
      console.warn('Failed to extract PO mappings from brackets:', e)
    }

    // 6-2. ì†ê¸€ì”¨ ì¢Œì¸¡ ë²ˆí˜¸/êµ¬ê°„ ì¶”ë¡  (í’ˆëª©ë³„ ë³´ê°•)
    let rangeMappings: RangeMapping[] = []
    try {
      rangeMappings = await extractPoRangesWithGPT4o(
        base64Image,
        normalizedItems,
        openaiApiKey
      )
    } catch (e) {
      console.warn('Failed to extract PO ranges from handwriting:', e)
    }

    // 6-3. ì¢Œì¸¡ ë²ˆí˜¸/êµ¬ê°„ ì¶”ë¡  + ê´„í˜¸ ë§¤í•‘ í•©ì˜ (í’ˆëª©ë³„ inferred ì •ë³´)
    const inferredPoMap = buildInferredPoMap({
      items: normalizedItems,
      visionWords,
      bracketMappings,
      rangeMappings
    })

    // 7. ê±°ë˜ì²˜ëª… ê²€ì¦ - vendors í…Œì´ë¸”ì— ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•¨
    currentStage = 'vendor_match'
    let validatedVendorName: string | undefined = undefined
    let validatedVendorId: number | undefined = undefined
    let vendorMatchSource: 'gpt_extract' | 'text_scan' | 'po_infer' | 'not_found' = 'not_found'
    
    // 7-1. GPTê°€ ì¶”ì¶œí•œ ê±°ë˜ì²˜ëª…ìœ¼ë¡œ ë¨¼ì € ì‹œë„ (í•œê¸€ëª…)
    if (extractionResult.vendor_name) {
      const vendorResult = await validateAndMatchVendor(
        supabase, 
        extractionResult.vendor_name
      )
      
      if (vendorResult.matched) {
        console.log(`âœ… ê±°ë˜ì²˜ ë§¤ì¹­ ì„±ê³µ (GPT ì¶”ì¶œ í•œê¸€): "${extractionResult.vendor_name}" â†’ "${vendorResult.vendor_name}" (${vendorResult.similarity}%)`)
        validatedVendorName = vendorResult.vendor_name
        validatedVendorId = vendorResult.vendor_id
        vendorMatchSource = 'gpt_extract'
      }
    }
    
    // 7-1-2. í•œê¸€ëª… ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì˜ë¬¸ëª…ìœ¼ë¡œ ì¬ì‹œë„
    if (!validatedVendorName && extractionResult.vendor_name_english) {
      const vendorResultEng = await validateAndMatchVendor(
        supabase, 
        extractionResult.vendor_name_english
      )
      
      if (vendorResultEng.matched) {
        console.log(`âœ… ê±°ë˜ì²˜ ë§¤ì¹­ ì„±ê³µ (GPT ì¶”ì¶œ ì˜ë¬¸): "${extractionResult.vendor_name_english}" â†’ "${vendorResultEng.vendor_name}" (${vendorResultEng.similarity}%)`)
        validatedVendorName = vendorResultEng.vendor_name
        validatedVendorId = vendorResultEng.vendor_id
        vendorMatchSource = 'gpt_extract'
      }
    }
    
    // 7-2. GPT ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ê±°ë˜ì²˜ ëª»ì°¾ìŒ â†’ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ vendors í…Œì´ë¸” ëŒ€ì¡°
    if (!validatedVendorName && visionText) {
      console.log('ğŸ“ ê±°ë˜ì²˜ ëª»ì°¾ìŒ - ì „ì²´ OCR í…ìŠ¤íŠ¸ì—ì„œ vendors í…Œì´ë¸” ëŒ€ì¡° ì‹œì‘...')
      const vendorFromText = await findVendorInText(supabase, visionText)
      
      if (vendorFromText.matched) {
        console.log(`âœ… ê±°ë˜ì²˜ ë§¤ì¹­ ì„±ê³µ (í…ìŠ¤íŠ¸ ìŠ¤ìº”): "${vendorFromText.matched_text}" â†’ "${vendorFromText.vendor_name}" (${vendorFromText.similarity}%)`)
        validatedVendorName = vendorFromText.vendor_name
        validatedVendorId = vendorFromText.vendor_id
        vendorMatchSource = 'text_scan'
      }
    }
    
    // 7-3. ê·¸ë˜ë„ ëª»ì°¾ìœ¼ë©´ ê²½ê³ 
    if (!validatedVendorName) {
      console.warn(`âš ï¸ ê±°ë˜ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ìˆ˜ë™ í™•ì¸ í•„ìš”`)
    }

    // 8. ë°œì£¼/ìˆ˜ì£¼ë²ˆí˜¸ ì˜¤ì¸ì‹ ë³´ì • (ê±°ë˜ì²˜/í’ˆëª©/ìˆ˜ëŸ‰ ê¸°ì¤€)
    const correctionResult = await correctOrderNumbersByDb(
      supabase,
      normalizedItems,
      validatedVendorId
    )
    normalizedItems = correctionResult.items
    if (correctionResult.inferredVendorName) {
      if (!validatedVendorName || validatedVendorName !== correctionResult.inferredVendorName) {
        validatedVendorName = correctionResult.inferredVendorName
        vendorMatchSource = 'po_infer'
      }
    }

    // 9. DBì— ê²°ê³¼ ì €ì¥ (ì—ëŸ¬ ì²´í¬ ì¶”ê°€)
    const { data: existingStatement } = await supabase
      .from('transaction_statements')
      .select('extracted_data')
      .eq('id', statementId)
      .single()

    const preservedActualReceivedDate = (existingStatement?.extracted_data as any)?.actual_received_date

    currentStage = 'db_update'
    // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œ: ê¸ˆì•¡ í•„ë“œëŠ” ëª¨ë‘ null, statement_modeëŠ” 'receipt'
    const { data: updateData, error: updateError } = await supabase
      .from('transaction_statements')
      .update({
        status: 'extracted',
        processing_finished_at: new Date().toISOString(),
        locked_by: null,
        reset_before_extract: false,
        statement_mode: 'receipt', // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œë¡œ ì„¤ì •
        statement_date: extractionResult.statement_date || null,
        vendor_name: validatedVendorName || null,
        total_amount: null,  // ê¸ˆì•¡ ì œì™¸
        tax_amount: null,    // ê¸ˆì•¡ ì œì™¸
        grand_total: null,   // ê¸ˆì•¡ ì œì™¸
        extracted_data: {
          ...extractionResult,
          ...(preservedActualReceivedDate ? { actual_received_date: preservedActualReceivedDate } : {}),
          items: normalizedItems.map(item => ({
            ...item,
            unit_price: null,  // ê¸ˆì•¡ ì œì™¸
            amount: null,      // ê¸ˆì•¡ ì œì™¸
            tax_amount: null   // ê¸ˆì•¡ ì œì™¸
          })),
          raw_vision_text: visionText,
          ocr_vendor_name: extractionResult.vendor_name,
          vendor_validated: !!validatedVendorName,
          vendor_match_source: vendorMatchSource,
          vendor_mismatch: !validatedVendorName
        }
      })
      .eq('id', statementId)
      .select()
      .single()

    if (updateError) {
      console.error('Failed to update transaction_statements:', updateError)
      return new Response(
        JSON.stringify({ 
          success: false, 
          error: `DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: ${updateError.message}. ê±°ë˜ëª…ì„¸ì„œ ë ˆì½”ë“œê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.` 
        }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    console.log('âœ… ê±°ë˜ëª…ì„¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ:', { id: statementId, vendor_name: validatedVendorName })

    // 10. ì¶”ì¶œëœ í’ˆëª©ë“¤ì„ transaction_statement_itemsì— ì €ì¥ (ê¸ˆì•¡ í•„ë“œ null)
    if (normalizedItems.length > 0) {
      currentStage = 'db_insert_items'
      const itemsToInsert = normalizedItems.map((item, idx) => {
        const lineNumber = item.line_number || idx + 1
        const inferredInfo = inferredPoMap.get(lineNumber)

        return {
          statement_id: statementId,
          line_number: lineNumber,
          extracted_item_name: item.item_name,
          extracted_specification: item.specification,
          extracted_quantity: item.quantity,
          extracted_unit_price: null,    // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œ: ê¸ˆì•¡ ì œì™¸
          extracted_amount: null,        // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œ: ê¸ˆì•¡ ì œì™¸
          extracted_tax_amount: null,    // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œ: ê¸ˆì•¡ ì œì™¸
          extracted_po_number: item.po_number,
          extracted_remark: item.remark,
          match_confidence: item.confidence,
          inferred_po_number: inferredInfo?.inferred_po_number || null,
          inferred_po_source: inferredInfo?.inferred_po_source || null,
          inferred_po_confidence: inferredInfo?.inferred_po_confidence ?? null,
          inferred_po_group_id: inferredInfo?.inferred_po_group_id || null
        }
      })

      const { error: itemsError } = await supabase
        .from('transaction_statement_items')
        .insert(itemsToInsert)

      if (itemsError) {
        console.error('Failed to insert items:', itemsError)
      }
    }

    if (statementId) {
      triggerNextQueuedProcessing(supabaseUrl, supabaseServiceKey)
    }

    return new Response(
      JSON.stringify({
        success: true,
        statementId: statementId,
        status: 'extracted',
        vendor_name: validatedVendorName || null, // ê²€ì¦ëœ ê±°ë˜ì²˜ëª… í¬í•¨
        vendor_match_source: vendorMatchSource, // ë§¤ì¹­ ë°©ë²•
        result: {
          ...extractionResult,
          vendor_name: validatedVendorName || null, // DBì— ì—†ìœ¼ë©´ vendor_name ë¹„ì›€
          items: normalizedItems
        }
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )

  } catch (error: any) {
    const errorMessage = `[stage:${currentStage}] ${error?.message || 'Unknown error'}`
    console.error('Error processing transaction statement:', error)

    // ì—ëŸ¬ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
    try {
      if (statementId) {
        const supabase = createClient(supabaseUrl, supabaseServiceKey)
        const retryCount = (claimedStatement?.retry_count ?? 0) + 1
        const delayMinutes = Math.min(30, Math.pow(2, Math.min(retryCount, 4)))
        const nextRetryAt = new Date(Date.now() + delayMinutes * 60 * 1000).toISOString()
        await supabase
          .from('transaction_statements')
          .update({ 
            status: 'failed',
            extraction_error: errorMessage,
            processing_finished_at: new Date().toISOString(),
            last_error_at: new Date().toISOString(),
            retry_count: retryCount,
            next_retry_at: nextRetryAt,
            locked_by: null,
            reset_before_extract: false
          })
          .eq('id', statementId)
      }
    } catch (e) {
      console.error('Failed to update error status:', e)
    }

    if (statementId) {
      triggerNextQueuedProcessing(supabaseUrl, supabaseServiceKey)
    }

    return new Response(
      JSON.stringify({ error: errorMessage }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  }
})

async function downloadImage(url: string): Promise<ArrayBuffer> {
  const response = await fetch(url)
  if (!response.ok) throw new Error(`Failed to download image: ${response.statusText}`)
  return await response.arrayBuffer()
}

function triggerNextQueuedProcessing(supabaseUrl: string, supabaseServiceKey: string) {
  // ì…ê³ ìˆ˜ëŸ‰ ëª¨ë“œ ì „ìš© í•¨ìˆ˜ í˜¸ì¶œ
  const functionUrl = `${supabaseUrl}/functions/v1/ocr-receipt-quantity`
  fetch(functionUrl, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${supabaseServiceKey}`,
      'apikey': supabaseServiceKey
    },
    body: JSON.stringify({ mode: 'process_next' })
  }).catch(() => {})
}

/**
 * ê±°ë˜ì²˜ëª… ê²€ì¦ - vendors í…Œì´ë¸”ì—ì„œ ìœ ì‚¬í•œ ê±°ë˜ì²˜ ì°¾ê¸°
 * ê±°ë˜ëª…ì„¸ì„œë¥¼ ë³´ë‚¸ ê±°ë˜ì²˜ëŠ” ë°˜ë“œì‹œ DBì— ì¡´ì¬í•´ì•¼ í•¨
 */
async function validateAndMatchVendor(
  supabase: any,
  extractedVendorName: string
): Promise<{ matched: boolean; vendor_name?: string; vendor_id?: number; similarity: number }> {
  if (!extractedVendorName) {
    return { matched: false, similarity: 0 }
  }

  // 1. vendors í…Œì´ë¸”ì—ì„œ ëª¨ë“  ê±°ë˜ì²˜ ì¡°íšŒ
  const { data: vendors, error } = await supabase
    .from('vendors')
    .select('id, vendor_name')
    .limit(500)

  if (error || !vendors || vendors.length === 0) {
    console.warn('Failed to fetch vendors or no vendors found:', error)
    return { matched: false, similarity: 0 }
  }

  // 2. ê° ê±°ë˜ì²˜ì™€ ìœ ì‚¬ë„ ê³„ì‚°
  let bestMatch: { vendor_id: number; vendor_name: string; similarity: number } | null = null

  for (const vendor of vendors) {
    const similarity = calculateVendorSimilarity(extractedVendorName, vendor.vendor_name)
    
    if (!bestMatch || similarity > bestMatch.similarity) {
      bestMatch = {
        vendor_id: vendor.id,
        vendor_name: vendor.vendor_name,
        similarity
      }
    }
  }

  // 3. ìœ ì‚¬ë„ 60% ì´ìƒì´ë©´ ë§¤ì¹­ ì„±ê³µ
  if (bestMatch && bestMatch.similarity >= 60) {
    return {
      matched: true,
      vendor_name: bestMatch.vendor_name,
      vendor_id: bestMatch.vendor_id,
      similarity: bestMatch.similarity
    }
  }

  return { matched: false, similarity: bestMatch?.similarity || 0 }
}

/**
 * ì „ì²´ OCR í…ìŠ¤íŠ¸ì—ì„œ vendors í…Œì´ë¸”ì˜ ê±°ë˜ì²˜ë¥¼ ì°¾ê¸°
 * ê±°ë˜ì²˜ëª…ì´ í…ìŠ¤íŠ¸ ì–´ë””ì—ë“  ìˆìœ¼ë©´ ì°¾ì•„ëƒ„
 */
async function findVendorInText(
  supabase: any,
  fullText: string
): Promise<{ matched: boolean; vendor_name?: string; vendor_id?: number; matched_text?: string; similarity: number }> {
  if (!fullText) {
    return { matched: false, similarity: 0 }
  }

  // 1. vendors í…Œì´ë¸”ì—ì„œ ëª¨ë“  ê±°ë˜ì²˜ ì¡°íšŒ
  const { data: vendors, error } = await supabase
    .from('vendors')
    .select('id, vendor_name')
    .limit(500)

  if (error || !vendors || vendors.length === 0) {
    console.warn('Failed to fetch vendors for text scan:', error)
    return { matched: false, similarity: 0 }
  }

  // 2. í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ê³  ê° ë¶€ë¶„ì—ì„œ ê±°ë˜ì²˜ ì°¾ê¸°
  const textLines = fullText.split(/[\n\r]+/).filter(line => line.trim().length > 0)
  
  let bestMatch: { 
    vendor_id: number; 
    vendor_name: string; 
    matched_text: string;
    similarity: number 
  } | null = null

  // ê° ê±°ë˜ì²˜ì— ëŒ€í•´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰
  for (const vendor of vendors) {
    const vendorName = vendor.vendor_name || ''
    if (!vendorName) continue
    
    // ê±°ë˜ì²˜ëª… ì •ê·œí™”
    const normalizedVendor = vendorName
      .toLowerCase()
      .replace(/\(ì£¼\)|ì£¼ì‹íšŒì‚¬|ãˆœ|ì£¼\)|co\.|ltd\.|inc\.|corp\.|company|ì»´í¼ë‹ˆ/gi, '')
      .replace(/[^a-z0-9ê°€-í£]/g, '')
      .trim()
    
    if (!normalizedVendor || normalizedVendor.length < 2) continue

    // ê° í…ìŠ¤íŠ¸ ë¼ì¸ì—ì„œ ê±°ë˜ì²˜ëª… ê²€ìƒ‰
    for (const line of textLines) {
      const normalizedLine = line
        .toLowerCase()
        .replace(/[^a-z0-9ê°€-í£\s]/g, '')
        .trim()
      
      // ê±°ë˜ì²˜ëª…ì´ ë¼ì¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
      if (normalizedLine.includes(normalizedVendor)) {
        const similarity = 100 // ì •í™•íˆ í¬í•¨
        if (!bestMatch || similarity > bestMatch.similarity) {
          bestMatch = {
            vendor_id: vendor.id,
            vendor_name: vendor.vendor_name,
            matched_text: line.trim(),
            similarity
          }
        }
        break // ì´ ê±°ë˜ì²˜ëŠ” ì°¾ì•˜ìœ¼ë‹ˆ ë‹¤ìŒ ê±°ë˜ì²˜ë¡œ
      }
      
      // ê±°ë˜ì²˜ëª…ì´ ë¼ì¸ì— ë¶€ë¶„ì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (4ê¸€ì ì´ìƒ)
      if (normalizedVendor.length >= 4) {
        const partialVendor = normalizedVendor.substring(0, Math.min(normalizedVendor.length, 6))
        if (normalizedLine.includes(partialVendor)) {
          const similarity = calculateVendorSimilarity(line, vendorName)
          if (similarity >= 70 && (!bestMatch || similarity > bestMatch.similarity)) {
            bestMatch = {
              vendor_id: vendor.id,
              vendor_name: vendor.vendor_name,
              matched_text: line.trim(),
              similarity
            }
          }
        }
      }
    }
  }

  if (bestMatch && bestMatch.similarity >= 70) {
    return {
      matched: true,
      vendor_name: bestMatch.vendor_name,
      vendor_id: bestMatch.vendor_id,
      matched_text: bestMatch.matched_text,
      similarity: bestMatch.similarity
    }
  }

  return { matched: false, similarity: bestMatch?.similarity || 0 }
}

/**
 * ê±°ë˜ì²˜ëª… ìœ ì‚¬ë„ ê³„ì‚° (0-100)
 * - íšŒì‚¬ ì ‘ë‘/ì ‘ë¯¸ì–´ ì œê±° í›„ ë¹„êµ
 * - ì˜ì–´ â†” í•œê¸€ ìŒì—­ ì§€ì›
 */
function calculateVendorSimilarity(vendor1: string, vendor2: string): number {
  if (!vendor1 || !vendor2) return 0
  
  // ì •ê·œí™”: íšŒì‚¬ ì ‘ë‘ì–´/ì ‘ë¯¸ì–´ ì œê±°
  const normalize = (name: string) => {
    return name
      .toLowerCase()
      .replace(/\(ì£¼\)|ì£¼ì‹íšŒì‚¬|ãˆœ|ì£¼\)|ì£¼|co\.|co,|ltd\.|ltd|inc\.|inc|corp\.|corp|company|ì»´í¼ë‹ˆ/gi, '')
      .replace(/[^a-z0-9ê°€-í£]/g, '') // íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ì œê±°
      .trim()
  }

  const n1 = normalize(vendor1)
  const n2 = normalize(vendor2)

  if (!n1 || !n2) return 0
  if (n1 === n2) return 100

  // í¬í•¨ ê´€ê³„
  if (n1.includes(n2) || n2.includes(n1)) {
    return 90
  }

  // ì˜ì–´ â†” í•œê¸€ ìŒì—­ ë§¤í•‘ (ê¸°ë³¸ì ì¸ ê²ƒë§Œ, AIê°€ ì˜ë¬¸ëª… ì¶”ì •í•˜ë¯€ë¡œ ìµœì†Œí™”)
  const translitMap: Record<string, string[]> = {
    'yg': ['ì™€ì´ì§€', 'yg'],
    'ì™€ì´ì§€': ['yg', 'ì™€ì´ì§€'],
    'tech': ['í…Œí¬', 'í…', 'tech'],
    'í…Œí¬': ['tech', 'í…', 'í…Œí¬'],
    'í…': ['tech', 'í…Œí¬', 'í…'],
    'high': ['í•˜ì´', 'high'],
    'í•˜ì´': ['high', 'í•˜ì´'],
    'korea': ['ì½”ë¦¬ì•„', 'í•œêµ­', 'korea'],
    'ì½”ë¦¬ì•„': ['korea', 'í•œêµ­', 'ì½”ë¦¬ì•„'],
    'electric': ['ì „ê¸°', 'ì¼ë ‰íŠ¸ë¦­', 'electric'],
    'ì „ê¸°': ['electric', 'ì¼ë ‰íŠ¸ë¦­', 'ì „ê¸°'],
    'steel': ['ìŠ¤í‹¸', 'ì² ê°•', 'steel'],
    'ìŠ¤í‹¸': ['steel', 'ì² ê°•', 'ìŠ¤í‹¸'],
    'metal': ['ë©”íƒˆ', 'ê¸ˆì†', 'metal'],
    'ë©”íƒˆ': ['metal', 'ê¸ˆì†', 'ë©”íƒˆ'],
    'system': ['ì‹œìŠ¤í…œ', 'system'],
    'ì‹œìŠ¤í…œ': ['system', 'ì‹œìŠ¤í…œ'],
    'soft': ['ì†Œí”„íŠ¸', 'soft'],
    'ì†Œí”„íŠ¸': ['soft', 'ì†Œí”„íŠ¸'],
    'net': ['ë„·', 'net'],
    'ë„·': ['net', 'ë„·'],
    'global': ['ê¸€ë¡œë²Œ', 'global'],
    'ê¸€ë¡œë²Œ': ['global', 'ê¸€ë¡œë²Œ'],
    'trade': ['íŠ¸ë ˆì´ë“œ', 'ë¬´ì—­', 'trade'],
    'íŠ¸ë ˆì´ë“œ': ['trade', 'ë¬´ì—­', 'íŠ¸ë ˆì´ë“œ'],
    'international': ['ì¸í„°ë‚´ì…”ë„', 'international'],
    'ì¸í„°ë‚´ì…”ë„': ['international', 'ì¸í„°ë‚´ì…”ë„'],
  }

  // ìŒì—­ ì¹˜í™˜ í›„ ë¹„êµ
  let n1Replaced = n1
  let n2Replaced = n2
  
  for (const [key, values] of Object.entries(translitMap)) {
    if (n1.includes(key)) {
      for (const val of values) {
        n1Replaced = n1Replaced.replace(key, val)
        if (n1Replaced === n2 || n2.includes(n1Replaced) || n1Replaced.includes(n2)) {
          return 85
        }
      }
      n1Replaced = n1 // ë¦¬ì…‹
    }
    if (n2.includes(key)) {
      for (const val of values) {
        n2Replaced = n2Replaced.replace(key, val)
        if (n1 === n2Replaced || n1.includes(n2Replaced) || n2Replaced.includes(n1)) {
          return 85
        }
      }
      n2Replaced = n2 // ë¦¬ì…‹
    }
  }

  // Levenshtein ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
  const maxLen = Math.max(n1.length, n2.length)
  const distance = levenshteinDistance(n1, n2)
  const similarity = ((maxLen - distance) / maxLen) * 100

  return Math.round(similarity)
}

/**
 * Levenshtein ê±°ë¦¬ ê³„ì‚°
 */
function levenshteinDistance(s1: string, s2: string): number {
  const m = s1.length
  const n = s2.length
  const dp: number[][] = []
  
  for (let i = 0; i <= m; i++) {
    dp[i] = [i]
  }
  for (let j = 0; j <= n; j++) {
    dp[0][j] = j
  }
  
  for (let i = 1; i <= m; i++) {
    for (let j = 1; j <= n; j++) {
      if (s1[i - 1] === s2[j - 1]) {
        dp[i][j] = dp[i - 1][j - 1]
      } else {
        dp[i][j] = Math.min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1
      }
    }
  }
  
  return dp[m][n]
}

function arrayBufferToBase64(buffer: ArrayBuffer): string {
  return uint8ArrayToBase64(new Uint8Array(buffer))
}

function uint8ArrayToBase64(bytes: Uint8Array): string {
  let binary = ''
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i])
  }
  return btoa(binary)
}

async function decodeImageFromBuffer(buffer: ArrayBuffer): Promise<Image | null> {
  try {
    return await Image.decode(new Uint8Array(buffer))
  } catch (_) {
    return null
  }
}

async function encodeImageToBase64(image: Image): Promise<string> {
  const encoded = await image.encode(1)
  return uint8ArrayToBase64(encoded)
}

function applyContrast(image: Image, contrast: number): void {
  const factor = (259 * (contrast + 255)) / (255 * (259 - contrast))
  const data = image.bitmap
  for (let i = 0; i < data.length; i += 4) {
    data[i] = clampColor(factor * (data[i] - 128) + 128)
    data[i + 1] = clampColor(factor * (data[i + 1] - 128) + 128)
    data[i + 2] = clampColor(factor * (data[i + 2] - 128) + 128)
  }
}

function applySharpen(image: Image): void {
  const width = image.width
  const height = image.height
  const data = image.bitmap
  const output = new Uint8ClampedArray(data.length)
  output.set(data)

  for (let y = 1; y < height - 1; y += 1) {
    for (let x = 1; x < width - 1; x += 1) {
      const idx = (y * width + x) * 4
      for (let c = 0; c < 3; c += 1) {
        const center = data[idx + c]
        const top = data[((y - 1) * width + x) * 4 + c]
        const bottom = data[((y + 1) * width + x) * 4 + c]
        const left = data[(y * width + (x - 1)) * 4 + c]
        const right = data[(y * width + (x + 1)) * 4 + c]
        const value = (5 * center) - top - bottom - left - right
        output[idx + c] = clampColor(value)
      }
    }
  }

  data.set(output)
}

function clampColor(value: number): number {
  return Math.max(0, Math.min(255, Math.round(value)))
}

async function preprocessImage(image: Image): Promise<PreprocessResult | null> {
  const processed = image
  processed.saturation(0, true)
  applyContrast(processed, 30)

  const pixelCount = processed.width * processed.height
  if (pixelCount <= 6_000_000) {
    applySharpen(processed)
  }

  const maxDim = Math.max(processed.width, processed.height)
  const targetMaxDim = 2200
  if (maxDim > targetMaxDim) {
    const scaleFactor = targetMaxDim / maxDim
    processed.scale(scaleFactor, Image.RESIZE_NEAREST_NEIGHBOR)
  }

  const base64 = await encodeImageToBase64(processed)
  return { image: processed, base64 }
}

async function buildImageTiles(image: Image): Promise<ImageTile[]> {
  const tiles: ImageTile[] = []
  const maxDim = Math.max(image.width, image.height)
  if (image.width < 1200 || image.height < 1200) return tiles
  if (maxDim > 2200) return tiles

  const rows = 2
  const cols = 2
  const tileWidth = Math.ceil(image.width / cols)
  const tileHeight = Math.ceil(image.height / rows)

  for (let row = 0; row < rows; row += 1) {
    for (let col = 0; col < cols; col += 1) {
      const offsetX = col * tileWidth
      const offsetY = row * tileHeight
      const width = Math.min(tileWidth, image.width - offsetX)
      const height = Math.min(tileHeight, image.height - offsetY)
      if (width <= 0 || height <= 0) continue

      const tile = image.clone().crop(offsetX, offsetY, width, height)
      const base64 = await encodeImageToBase64(tile)
      tiles.push({ base64, offsetX, offsetY })
    }
  }

  return tiles
}

function offsetVisionWords(words: VisionWord[], offsetX: number, offsetY: number): VisionWord[] {
  return words.map((word) => ({
    ...word,
    bbox: {
      x: word.bbox.x + offsetX,
      y: word.bbox.y + offsetY,
      w: word.bbox.w,
      h: word.bbox.h
    }
  }))
}

async function callGoogleVision(base64Image: string, credentials: string): Promise<{ text: string; words: VisionWord[] }> {
  const credentialsJson = JSON.parse(credentials)
  
  // Google OAuth2 í† í° íšë“
  const tokenResponse = await fetch('https://oauth2.googleapis.com/token', {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: new URLSearchParams({
      grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',
      assertion: await createJWT(credentialsJson)
    })
  })

  const tokenData = await tokenResponse.json()
  if (!tokenData.access_token) {
    throw new Error('Failed to get Google access token')
  }

  // Vision API í˜¸ì¶œ
  const visionResponse = await fetch(
    'https://vision.googleapis.com/v1/images:annotate',
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.access_token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        requests: [{
          image: { content: base64Image },
          features: [{ type: 'DOCUMENT_TEXT_DETECTION' }],
          imageContext: {
            languageHints: ['ko', 'en']
          }
        }]
      })
    }
  )

  const visionResult = await visionResponse.json()
  const annotation = visionResult.responses?.[0]?.fullTextAnnotation
  const words = annotation ? extractVisionWords(annotation) : []

  if (annotation?.text) {
    return { text: annotation.text, words }
  }

  return { text: '', words }
}

function extractVisionWords(annotation: any): VisionWord[] {
  const words: VisionWord[] = []
  const pages = annotation?.pages || []

  pages.forEach((page: any) => {
    (page.blocks || []).forEach((block: any) => {
      (block.paragraphs || []).forEach((paragraph: any) => {
        (paragraph.words || []).forEach((word: any) => {
          const symbols = word.symbols || []
          const text = symbols.map((symbol: any) => symbol.text).join('')
          const vertices = word.boundingBox?.vertices || []
          if (!text || vertices.length === 0) return

          const xs = vertices.map((v: any) => v.x ?? 0)
          const ys = vertices.map((v: any) => v.y ?? 0)
          const minX = Math.min(...xs)
          const maxX = Math.max(...xs)
          const minY = Math.min(...ys)
          const maxY = Math.max(...ys)

          words.push({
            text,
            bbox: {
              x: minX,
              y: minY,
              w: Math.max(1, maxX - minX),
              h: Math.max(1, maxY - minY)
            }
          })
        })
      })
    })
  })

  return words
}

async function createJWT(credentials: any): Promise<string> {
  const header = { alg: 'RS256', typ: 'JWT' }
  const now = Math.floor(Date.now() / 1000)
  const payload = {
    iss: credentials.client_email,
    scope: 'https://www.googleapis.com/auth/cloud-vision',
    aud: 'https://oauth2.googleapis.com/token',
    exp: now + 3600,
    iat: now
  }

  const encoder = new TextEncoder()
  const headerB64 = btoa(JSON.stringify(header))
  const payloadB64 = btoa(JSON.stringify(payload))
  const signatureInput = encoder.encode(`${headerB64}.${payloadB64}`)

  // Import private key
  const privateKeyPem = credentials.private_key
  const privateKeyDer = pemToDer(privateKeyPem)
  
  const cryptoKey = await crypto.subtle.importKey(
    'pkcs8',
    privateKeyDer,
    { name: 'RSASSA-PKCS1-v1_5', hash: 'SHA-256' },
    false,
    ['sign']
  )

  const signature = await crypto.subtle.sign(
    'RSASSA-PKCS1-v1_5',
    cryptoKey,
    signatureInput
  )

  const signatureB64 = btoa(String.fromCharCode(...new Uint8Array(signature)))
    .replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=/g, '')

  return `${headerB64}.${payloadB64}.${signatureB64}`
}

function pemToDer(pem: string): ArrayBuffer {
  const base64 = pem
    .replace('-----BEGIN PRIVATE KEY-----', '')
    .replace('-----END PRIVATE KEY-----', '')
    .replace(/\s/g, '')
  
  const binary = atob(base64)
  const buffer = new ArrayBuffer(binary.length)
  const view = new Uint8Array(buffer)
  for (let i = 0; i < binary.length; i++) {
    view[i] = binary.charCodeAt(i)
  }
  return buffer
}

async function extractWithGPT4o(
  base64Image: string, 
  visionText: string, 
  apiKey: string,
  poScope: 'single' | 'multi' | null
): Promise<ExtractionResult> {
  const scopeHint = poScope === 'single'
    ? 'ì´ ê±°ë˜ëª…ì„¸ì„œëŠ” ë‹¨ì¼ ë°œì£¼/ìˆ˜ì£¼ ê±´ì…ë‹ˆë‹¤. ë°œì£¼/ìˆ˜ì£¼ë²ˆí˜¸ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë©°, ëª¨ë“  í’ˆëª©ì€ ë™ì¼í•œ ë°œì£¼/ìˆ˜ì£¼ë¡œ ì·¨ê¸‰í•˜ì„¸ìš”.'
    : poScope === 'multi'
    ? 'ì´ ê±°ë˜ëª…ì„¸ì„œëŠ” ë‹¤ì¤‘ ë°œì£¼/ìˆ˜ì£¼ ê±´ì…ë‹ˆë‹¤. ì„œë¡œ ë‹¤ë¥¸ ë°œì£¼/ìˆ˜ì£¼ë²ˆí˜¸ê°€ ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê° í’ˆëª©ë³„ë¡œ ë¶„ë¦¬í•´ ì¶”ì¶œí•˜ì„¸ìš”.'
    : ''
  // ì…ê³ ìˆ˜ëŸ‰ ì—…ë¡œë“œìš© í”„ë¡¬í”„íŠ¸ - ê¸ˆì•¡ ì¶”ì¶œ ì œì™¸
  const prompt = `ê±°ë˜ëª…ì„¸ì„œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. **ì…ê³ ìˆ˜ëŸ‰ í™•ì¸ìš©**ìœ¼ë¡œ ìˆ˜ëŸ‰ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. ê¸ˆì•¡/ë‹¨ê°€ëŠ” ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”.

${scopeHint ? `âš ï¸ **ë°œì£¼/ìˆ˜ì£¼ ë²”ìœ„ íŒíŠ¸:** ${scopeHint}` : ''}

âš ï¸ **ê±°ë˜ì²˜(ê³µê¸‰ì) ì‹ë³„ ë°©ë²• - ë§¤ìš° ì¤‘ìš”:**
í•œêµ­ ê±°ë˜ëª…ì„¸ì„œì—ëŠ” ë‘ íšŒì‚¬ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤:
- "ê·€ì¤‘" ë˜ëŠ” "ê·€ì‚¬" ì˜†ì— ìˆëŠ” íšŒì‚¬ = **ë°›ëŠ” ì‚¬ëŒ (êµ¬ë§¤ì)** â†’ ì´ê±´ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”!
- "ê³µê¸‰ì", "ê³µê¸‰í•˜ëŠ” ì", "(ì¸)", ë˜ëŠ” ë„ì¥/ì§ì¸ì´ ìˆëŠ” ìª½ = **ê³µê¸‰ì (íŒë§¤ì)** â†’ ì´ê²ƒì´ vendor_nameì…ë‹ˆë‹¤!
ê±°ë˜ëª…ì„¸ì„œë¥¼ **ë³´ë‚´ì˜¨ íšŒì‚¬**ê°€ ê³µê¸‰ìì…ë‹ˆë‹¤. "ê·€ì¤‘" ì˜†ì— ìˆëŠ” íšŒì‚¬ëŠ” ë°›ëŠ” íšŒì‚¬ì´ë¯€ë¡œ vendor_nameìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.

ì¶”ì¶œ ëŒ€ìƒ (ê¸ˆì•¡ ì œì™¸):
1. statement_date: ê±°ë˜ëª…ì„¸ì„œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
2. vendor_name: **ê³µê¸‰ì(íŒë§¤ì)** ìƒí˜¸/íšŒì‚¬ëª… - ë„ì¥/ì§ì¸/ëŒ€í‘œìëª…ì´ ìˆëŠ” ìª½!
3. vendor_name_english: í•œê¸€ íšŒì‚¬ëª…ì˜ ì˜ë¬¸ í‘œê¸° ì¶”ì •
4. items: í’ˆëª© ë°°ì—´ (ìˆ˜ëŸ‰ë§Œ ì¶”ì¶œ, ê¸ˆì•¡ ì œì™¸)

âš ï¸ **í•œê¸€ íšŒì‚¬ëª… ì •í™•íˆ ì½ê¸° - ë§¤ìš° ì¤‘ìš”:**
- ë¹„ìŠ·í•˜ê²Œ ìƒê¸´ ê¸€ì ì£¼ì˜: ì—”/í”Œ, ì—/ì• , ìŠ¤/ì¦ˆ, í…Œí¬/í… ë“±
- ê¸€ì í•˜ë‚˜í•˜ë‚˜ ì •í™•íˆ í™•ì¸í•˜ê³  ì½ì–´ì£¼ì„¸ìš”
- í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ìì„¸íˆ ë´ì£¼ì„¸ìš”

âš ï¸ **ì¹¼ëŸ¼ í—¤ë”ë¥¼ ë°˜ë“œì‹œ ë¨¼ì € ì½ê³  ë°ì´í„° ì¶”ì¶œ - ê°€ì¥ ì¤‘ìš”:**
1. í…Œì´ë¸”ì˜ **í—¤ë” í–‰**ì„ ë¨¼ì € ì½ì–´ì„œ ê° ì¹¼ëŸ¼ì´ ë¬´ì—‡ì¸ì§€ íŒŒì•…í•˜ì„¸ìš”
2. í—¤ë”ëª…ì€ ì—…ì²´ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
   - í’ˆëª©ëª…: "í’ˆëª…", "í’ˆëª©", "ë‚´ì—­", "DESCRIPTION", "ìƒí’ˆëª…" ë“±
   - ê·œê²©: "ê·œê²©", "SIZE", "ì‚¬ì´ì¦ˆ", "ì¹˜ìˆ˜", "SPEC" ë“±  
   - ìˆ˜ëŸ‰: "ìˆ˜ëŸ‰", "QTY", "ìˆ˜", "Q'TY", "QUANTITY" ë“±
3. **í—¤ë”ëª…ì„ ë³´ê³  ê° ì—´ì´ ë¬´ì—‡ì¸ì§€ ì •í™•íˆ íŒŒì•…í•œ í›„** ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”!

âš ï¸ **ìˆ˜ëŸ‰(QTY) ì¹¼ëŸ¼ ì •í™•íˆ ì°¾ê¸° - ì ˆëŒ€ í‹€ë¦¬ë©´ ì•ˆë¨:**
- ìˆ˜ëŸ‰ì€ **í—¤ë”ì— "ìˆ˜ëŸ‰" ë˜ëŠ” "QTY"**ë¼ê³  ì í˜€ ìˆëŠ” ì¹¼ëŸ¼ì…ë‹ˆë‹¤
- ìˆ˜ëŸ‰ ê°’ì€ í•­ìƒ **ìˆœìˆ˜í•œ ì •ìˆ˜** (1, 5, 10, 15, 100 ë“±)
- ê·œê²© ì¹¼ëŸ¼ì— ìˆëŠ” ìˆ«ì(ì˜ˆ: 110, 200mm)ë¥¼ ìˆ˜ëŸ‰ìœ¼ë¡œ ì°©ê°í•˜ì§€ ë§ˆì„¸ìš”!
- **í—¤ë”ë¥¼ ë¬´ì‹œí•˜ê³  ìˆœì„œë¡œë§Œ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”!**

ê° í’ˆëª©(item)ì—ì„œ ì¶”ì¶œ (ê¸ˆì•¡ í•„ë“œ ì œì™¸):
- line_number: ìˆœë²ˆ
- item_name: í’ˆëª©ëª…/í’ˆëª…
- specification: ê·œê²©/SIZE (ì˜ˆ: 197X, 100mm, 110x50 ë“±) - ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
- quantity: ìˆ˜ëŸ‰/QTY (ì •ìˆ˜, ì£¼ë¬¸ ê°œìˆ˜) â­ ê°€ì¥ ì¤‘ìš”!
- po_number: ë°œì£¼ë²ˆí˜¸ ë˜ëŠ” ìˆ˜ì£¼ë²ˆí˜¸
- remark: ë¹„ê³  ì „ì²´ ë‚´ìš©
- confidence: ì¶”ì¶œ í™•ì‹ ë„ ("low", "med", "high")

âš ï¸ **ê¸ˆì•¡ ê´€ë ¨ í•„ë“œëŠ” ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”:** unit_price, amount, tax_amount, total_amount, grand_total ë“±

âš ï¸ ë°œì£¼ë²ˆí˜¸/ìˆ˜ì£¼ë²ˆí˜¸ ì°¾ëŠ” ë°©ë²• (ì¤‘ìš”):
- ë°œì£¼ë²ˆí˜¸ íŒ¨í„´: F + ë‚ ì§œ(YYYYMMDD) + _ + ìˆ«ì (ì˜ˆ: F20251010_001, F20251010_1) - ì‹œìŠ¤í…œì€ í•­ìƒ 3ìë¦¬(_001)
- ìˆ˜ì£¼ë²ˆí˜¸ íŒ¨í„´: HS + ë‚ ì§œ(YYMMDD, 6ìë¦¬) + - + ìˆ«ì (ì˜ˆ: HS251201-01, HS251201-1) - ì‹œìŠ¤í…œì€ í•­ìƒ 2ìë¦¬(-01)
- ë¹„ê³ ë€ë¿ ì•„ë‹ˆë¼ ë¹ˆ ì¹¸, ì—¬ë°±, í’ˆëª©ëª… ì˜† ë“± **ë¬¸ì„œ ì–´ë””ì—ë“ ** ì†ê¸€ì”¨/í•„ê¸°ì²´ë¡œ ì í˜€ìˆì„ ìˆ˜ ìˆìŒ
- ê° í’ˆëª© í–‰ì˜ ê°™ì€ ì¤„ì— ìˆëŠ” ì†ê¸€ì”¨ ë²ˆí˜¸ë¥¼ í•´ë‹¹ í’ˆëª©ì˜ po_numberë¡œ ë§¤ì¹­
- ì—¬ëŸ¬ í’ˆëª©ì— ê°™ì€ ë²ˆí˜¸ê°€ ì í˜€ìˆìœ¼ë©´ ëª¨ë‘ í•´ë‹¹ ë²ˆí˜¸ë¥¼ ê¸°ë¡
- ë²ˆí˜¸ê°€ íë¦¬ê±°ë‚˜ ë¶ˆë¶„ëª…í•´ë„ íŒ¨í„´ì— ë§ìœ¼ë©´ ìµœëŒ€í•œ ì½ì–´ì„œ ê¸°ë¡ (confidence: "low")

ì†ê¸€ì”¨/í•„ê¸°ì²´ë¡œ ì íŒ ë²ˆí˜¸ë„ ìµœëŒ€í•œ ì½ì–´ì£¼ì„¸ìš”.
í™•ì‹ ë„(confidence)ëŠ” ê¸€ì”¨ê°€ ë¶ˆëª…í™•í•˜ê±°ë‚˜ ì¶”ì¸¡ì´ í•„ìš”í•œ ê²½ìš° "low", ë³´í†µì´ë©´ "med", ëª…í™•í•˜ë©´ "high"ë¡œ í‘œì‹œí•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ì´ê²ƒì€ **ì…ê³ ìˆ˜ëŸ‰ í™•ì¸ìš©**ì…ë‹ˆë‹¤. ê¸ˆì•¡(unit_price, amount, tax_amount ë“±)ì€ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”!

${visionText ? `
âš ï¸ **OCR í…ìŠ¤íŠ¸ ìš°ì„  ì°¸ì¡° - ê±°ë˜ì²˜ëª… ì¶”ì¶œ ì‹œ ë§¤ìš° ì¤‘ìš”:**
ì•„ë˜ëŠ” Google Vision OCRì´ ì½ì€ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì™€ ë‹¤ë¥´ê²Œ ë³´ì´ë©´ **OCR í…ìŠ¤íŠ¸ë¥¼ ì‹ ë¢°**í•˜ì„¸ìš”.
íŠ¹íˆ ê±°ë˜ì²˜ëª…(vendor_name)ì€ OCR í…ìŠ¤íŠ¸ì—ì„œ ë¨¼ì € ì°¾ì•„ì£¼ì„¸ìš”.
---
${visionText.substring(0, 3000)}
---` : ''}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.`

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        { 
          role: 'system', 
          content: 'You are an expert at extracting structured data from Korean transaction statements (ê±°ë˜ëª…ì„¸ì„œ). Always respond with valid JSON only.' 
        },
        { 
          role: 'user', 
          content: [
            { type: 'text', text: prompt },
            { 
              type: 'image_url', 
              image_url: { 
                url: `data:image/png;base64,${base64Image}`,
                detail: 'high'
              } 
            }
          ]
        }
      ],
      temperature: 0.1,
      max_tokens: 4000,
      response_format: { type: 'json_object' }
    })
  })

  const result = await response.json()
  
  if (result.error) {
    throw new Error(`GPT-4o error: ${result.error.message}`)
  }

  const content = result.choices?.[0]?.message?.content
  if (!content) {
    throw new Error('No content in GPT-4o response')
  }

  return JSON.parse(content)
}

type PoMapping = {
  line_number?: number
  start_line?: number
  end_line?: number
  item_name?: string
  po_number?: string
  confidence?: number
}

type RangeMapping = {
  po_number?: string
  start_line?: number
  end_line?: number
  confidence?: number
}

async function extractPoMappingsWithGPT4o(
  base64Image: string,
  items: ExtractedItem[],
  apiKey: string
): Promise<PoMapping[]> {
  const itemHints = items.map((item) => ({
    line_number: item.line_number,
    item_name: item.item_name
  }))

  const prompt = `ê±°ë˜ëª…ì„¸ì„œ ì´ë¯¸ì§€ì—ì„œ ì†ê¸€ì”¨ ê´„í˜¸/ì—°ê²°ì„ ìœ¼ë¡œ í‘œì‹œëœ "ë°œì£¼ë²ˆí˜¸/ìˆ˜ì£¼ë²ˆí˜¸ í¬í•¨ ê´€ê³„"ë¥¼ ì½ì–´,
ì•„ë˜ item ëª©ë¡ì— ëŒ€í•´ í’ˆëª©ë³„ po_numberë¥¼ ë§¤í•‘í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1) ì†ê¸€ì”¨ë¡œ ì íŒ ë²ˆí˜¸(F########_### ë˜ëŠ” HS######-##)ì™€ ê´„í˜¸/ì—°ê²°ì„ ì´ ê°€ë¦¬í‚¤ëŠ” í’ˆëª©ë“¤ì„ ë¬¶ì–´ì£¼ì„¸ìš”.
2) ë²ˆí˜¸ê°€ í’ˆëª© ì˜†ì´ ì•„ë‹ˆë¼ ë‘ë²ˆì§¸ ì¤„ì— ì í˜€ ìˆì–´ë„, ê´„í˜¸/ì—°ê²°ì„ ì´ ìœ„ìª½ í’ˆëª©ê¹Œì§€ ì´ì–´ì§€ë©´ ìœ„ìª½ í–‰ë„ í¬í•¨í•˜ì„¸ìš”.
3) line_numberëŠ” ë¬¸ì„œì˜ í–‰ ìˆœì„œì…ë‹ˆë‹¤. ì—¬ëŸ¬ í–‰ ë¬¶ìŒì€ start_line/end_line ë²”ìœ„ë¡œ ë°˜í™˜í•´ë„ ë©ë‹ˆë‹¤.
4) ë§¤í•‘ì´ í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸í•˜ì„¸ìš”.
5) ê²°ê³¼ëŠ” ì•„ë˜ JSON í˜•ì‹ë§Œ ë°˜í™˜:
{"mappings":[{"start_line":1,"end_line":4,"po_number":"F... ë˜ëŠ” HS...","confidence":0~1},{"line_number":ë²ˆí˜¸,"item_name":"í’ˆëª©ëª…","po_number":"F... ë˜ëŠ” HS...","confidence":0~1}]}

item ëª©ë¡:
${JSON.stringify(itemHints)}
`

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'You extract handwritten bracket-to-item mappings.' },
        { role: 'user', content: [
          { type: 'text', text: prompt },
          { type: 'image_url', image_url: { url: `data:image/png;base64,${base64Image}`, detail: 'high' } }
        ] }
      ],
      temperature: 0.1,
      max_tokens: 1200,
      response_format: { type: 'json_object' }
    })
  })

  const result = await response.json()
  if (result.error) {
    throw new Error(`GPT-4o error (mapping): ${result.error.message}`)
  }
  const content = result.choices?.[0]?.message?.content
  if (!content) return []
  const parsed = JSON.parse(content)
  return Array.isArray(parsed.mappings) ? parsed.mappings : []
}

async function extractPoRangesWithGPT4o(
  base64Image: string,
  items: ExtractedItem[],
  apiKey: string
): Promise<RangeMapping[]> {
  const itemHints = items.map((item) => ({
    line_number: item.line_number,
    item_name: item.item_name
  }))

  const prompt = `ê±°ë˜ëª…ì„¸ì„œ ì´ë¯¸ì§€ì—ì„œ ì™¼ìª½ ì—¬ë°±ì— ì†ê¸€ì”¨ë¡œ ì íŒ ë°œì£¼/ìˆ˜ì£¼ë²ˆí˜¸ê°€ ìˆê³ ,
ê·¸ ì•„ë˜ ì—¬ëŸ¬ í’ˆëª©ì— ê°™ì€ ë²ˆí˜¸ê°€ ì ìš©ë˜ëŠ” ê²½ìš°ë¥¼ ì°¾ì•„ line_number ë²”ìœ„ë¥¼ ì¶”ë¡ í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1) ë²ˆí˜¸ëŠ” F########_### ë˜ëŠ” HS######-## í˜•ì‹ì…ë‹ˆë‹¤.
2) ë²ˆí˜¸ê°€ ì¤‘ê°„ì— ë°”ë€Œë©´ ì—¬ëŸ¬ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”.
3) í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸í•˜ì„¸ìš”.
4) ê²°ê³¼ëŠ” ì•„ë˜ JSON í˜•ì‹ë§Œ ë°˜í™˜:
{"ranges":[{"po_number":"F... ë˜ëŠ” HS...","start_line":1,"end_line":5,"confidence":0~1}]}

item ëª©ë¡:
${JSON.stringify(itemHints)}
`

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'You detect handwritten margin order numbers and their line ranges.' },
        { role: 'user', content: [
          { type: 'text', text: prompt },
          { type: 'image_url', image_url: { url: `data:image/png;base64,${base64Image}`, detail: 'high' } }
        ] }
      ],
      temperature: 0.1,
      max_tokens: 1200,
      response_format: { type: 'json_object' }
    })
  })

  const result = await response.json()
  if (result.error) {
    throw new Error(`GPT-4o error (range mapping): ${result.error.message}`)
  }
  const content = result.choices?.[0]?.message?.content
  if (!content) return []
  const parsed = JSON.parse(content)
  return Array.isArray(parsed.ranges) ? parsed.ranges : []
}

function shouldRetryOrderNumberPass(items: ExtractedItem[]): boolean {
  if (!items.length) return false
  const lowConfidenceCount = items.filter((item) => item.confidence === 'low').length
  const missingCount = items.filter((item) => !item.po_number).length
  const lowConfidenceRatio = lowConfidenceCount / items.length
  const missingRatio = missingCount / items.length
  return missingRatio >= 0.4 || lowConfidenceRatio >= 0.4 || missingCount === items.length
}

async function extractOrderNumbersWithGPT4o(
  base64Image: string,
  tileImages: string[],
  apiKey: string
): Promise<string[]> {
  const prompt = `ê±°ë˜ëª…ì„¸ì„œ ì´ë¯¸ì§€ì—ì„œ ì†ê¸€ì”¨/í•„ê¸°ì²´ë¡œ ì íŒ ë°œì£¼ë²ˆí˜¸ ë˜ëŠ” ìˆ˜ì£¼ë²ˆí˜¸ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ê·œì¹™:
1) ë²ˆí˜¸ íŒ¨í„´ë§Œ ë°˜í™˜: F########_### ë˜ëŠ” HS######-## í˜•íƒœ
2) ë¶ˆí™•ì‹¤í•˜ë©´ ì œì™¸í•˜ì„¸ìš”.
3) ê²°ê³¼ëŠ” ì•„ë˜ JSON í˜•ì‹ë§Œ ë°˜í™˜:
{"numbers":["F...","HS..."]}
`

  const imageContents = [
    { type: 'image_url', image_url: { url: `data:image/png;base64,${base64Image}`, detail: 'high' } }
  ]

  tileImages.slice(0, 4).forEach((tile) => {
    imageContents.push({
      type: 'image_url',
      image_url: { url: `data:image/png;base64,${tile}`, detail: 'high' }
    })
  })

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'You only extract handwritten order numbers.' },
        { role: 'user', content: [
          { type: 'text', text: prompt },
          ...imageContents
        ] }
      ],
      temperature: 0.1,
      max_tokens: 800,
      response_format: { type: 'json_object' }
    })
  })

  const result = await response.json()
  if (result.error) {
    throw new Error(`GPT-4o error (numbers): ${result.error.message}`)
  }
  const content = result.choices?.[0]?.message?.content
  if (!content) return []
  const parsed = JSON.parse(content)
  return Array.isArray(parsed.numbers) ? parsed.numbers : []
}

function normalizePO(num: string): string {
  const match = num.toUpperCase().match(/^(F\d{8})_(\d{1,3})$/)
  if (match) {
    return `${match[1]}_${match[2].padStart(3, '0')}`
  }
  return num.toUpperCase()
}

function normalizeSO(num: string): string {
  const match = num.toUpperCase().match(/^(HS\d{6})-(\d{1,2})$/)
  if (match) {
    return `${match[1]}-${match[2].padStart(2, '0')}`
  }
  return num.toUpperCase()
}

function normalizePoNumbers(
  items: ExtractedItem[],
  rawVisionText?: string,
  extraNumbers: string[] = []
): ExtractedItem[] {
  // ë°œì£¼ë²ˆí˜¸ íŒ¨í„´: F + YYYYMMDD + _ + 1~3ìë¦¬ ìˆ«ì (OCRì—ì„œ ì½íŒ í˜•íƒœ)
  const poPatternLoose = /F\d{8}_\d{1,3}/gi
  // ìˆ˜ì£¼ë²ˆí˜¸ íŒ¨í„´: HS + YYMMDD + - + 1~2ìë¦¬ ìˆ«ì (OCRì—ì„œ ì½íŒ í˜•íƒœ)
  const soPatternLoose = /HS\d{6}-\d{1,2}/gi

  // ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  PO/SO ë²ˆí˜¸ ì¶”ì¶œ (ë¹ˆ ì¹¸, ì—¬ë°± ë“±ì—ì„œ ë°œê²¬ëœ ë²ˆí˜¸ë“¤)
  const allFoundNumbers: string[] = []
  if (rawVisionText) {
    const poMatches = rawVisionText.match(poPatternLoose) || []
    const soMatches = rawVisionText.match(soPatternLoose) || []
    allFoundNumbers.push(...poMatches.map(n => normalizePO(n)))
    allFoundNumbers.push(...soMatches.map(n => normalizeSO(n)))
  }
  if (extraNumbers.length > 0) {
    extraNumbers.forEach((value) => {
      const normalized = normalizeMappedNumber(value)
      if (normalized) allFoundNumbers.push(normalized)
    })
  }

  return items.map((item, idx) => {
    let poNumber = item.po_number

    if (poNumber) {
      // íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì •ê·œí™”
      let normalized = poNumber.toUpperCase().replace(/\s+/g, '').replace(/[^\w_-]/g, '')
      
      // ë°œì£¼ë²ˆí˜¸ íŒ¨í„´ ì²´í¬ ë° ì •ê·œí™”
      const poMatch = normalized.match(poPatternLoose)
      if (poMatch) {
        poNumber = normalizePO(poMatch[0])
      } else {
        // ìˆ˜ì£¼ë²ˆí˜¸ íŒ¨í„´ ì²´í¬ ë° ì •ê·œí™”
        const soMatch = normalized.match(soPatternLoose)
        if (soMatch) {
          poNumber = normalizeSO(soMatch[0])
        } else {
          poNumber = normalized
        }
      }
    } else if (allFoundNumbers.length > 0) {
      // í’ˆëª©ì— ë²ˆí˜¸ê°€ ì—†ì§€ë§Œ ì „ì²´ ë¬¸ì„œì—ì„œ ë²ˆí˜¸ê°€ ë°œê²¬ëœ ê²½ìš°
      // ë‹¨ì¼ ë²ˆí˜¸ë§Œ ìˆìœ¼ë©´ ëª¨ë“  í’ˆëª©ì— ì ìš© (í•˜ë‚˜ì˜ ë°œì£¼ì— ëŒ€í•œ ê±°ë˜ëª…ì„¸ì„œ)
      const uniqueCount = new Set(allFoundNumbers).size
      if (uniqueCount === 1) {
        poNumber = allFoundNumbers[0]
      } else if (allFoundNumbers.length === items.length && uniqueCount === items.length) {
        // ë²ˆí˜¸ ê°œìˆ˜ì™€ í’ˆëª© ê°œìˆ˜ê°€ ê°™ê³  ì¤‘ë³µì´ ì—†ìœ¼ë©´ ìˆœì„œëŒ€ë¡œ ë§¤ì¹­
        poNumber = allFoundNumbers[idx]
      }
      // ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” ìˆ˜ë™ ë§¤ì¹­ í•„ìš”
    }

    return {
      ...item,
      po_number: poNumber || item.po_number
    }
  })
}

type OrderCorrectionResult = {
  items: ExtractedItem[];
  inferredVendorName?: string;
};

async function correctOrderNumbersByDb(
  supabase: any,
  items: ExtractedItem[],
  vendorId?: number
): Promise<OrderCorrectionResult> {
  if (!items.length) return { items };

  const numberCounts = new Map<string, number>();
  items.forEach(item => {
    if (item.po_number) {
      numberCounts.set(item.po_number, (numberCounts.get(item.po_number) || 0) + 1);
    }
  });

  const mostCommon = Array.from(numberCounts.entries()).sort((a, b) => b[1] - a[1])[0]?.[0];
  if (!mostCommon) return { items };

  const isPO = /^F\d{8}_\d{3}$/.test(mostCommon);
  const isSO = /^HS\d{6}-\d{2}$/.test(mostCommon);
  if (!isPO && !isSO) return { items };

  const { data: exactMatch } = await supabase
    .from('purchase_requests')
    .select('id, vendor:vendors(vendor_name)')
    .or(`purchase_order_number.eq.${mostCommon},sales_order_number.eq.${mostCommon}`)
    .limit(1);

  if (exactMatch && exactMatch.length > 0) {
    const vendorName = (exactMatch[0].vendor as { vendor_name?: string } | null)?.vendor_name;
    return {
      items,
      inferredVendorName: vendorName
    };
  }

  const prefix = isPO ? mostCommon.slice(0, 9) : mostCommon.slice(0, 8);
  let query = supabase
    .from('purchase_requests')
    .select(`
      id,
      purchase_order_number,
      sales_order_number,
      vendor:vendors(vendor_name),
      items:purchase_request_items(
        id,
        item_name,
        specification,
        quantity
      )
    `)
    .limit(30);

  query = isPO
    ? query.ilike('purchase_order_number', `${prefix}%`)
    : query.ilike('sales_order_number', `${prefix}%`);

  if (vendorId) {
    query = query.eq('vendor_id', vendorId);
  }

  const { data: candidates } = await query;
  if (!candidates || candidates.length === 0) return { items };

  const cleanedItems = items.map(item => ({
    name: normalizeItemText(item.item_name || ''),
    quantity: item.quantity || 0
  }));

  let bestCandidate: any = null;
  let bestScore = 0;

  for (const candidate of candidates) {
    const systemItems = (candidate.items || []).map((it: any) => ({
      name: normalizeItemText(it.item_name || ''),
      spec: normalizeItemText(it.specification || ''),
      quantity: it.quantity || 0
    }));

    const { score, matchedCount } = calculateOrderSimilarity(cleanedItems, systemItems);
    if (matchedCount === 0) continue;

    if (score > bestScore) {
      bestScore = score;
      bestCandidate = candidate;
    }
  }

  if (!bestCandidate || bestScore < 65) {
    return { items };
  }

  const correctedNumber = isPO
    ? (bestCandidate.purchase_order_number || '')
    : (bestCandidate.sales_order_number || '');

  if (!correctedNumber) {
    return { items };
  }

  const correctedItems = items.map(item => ({
    ...item,
    po_number: correctedNumber
  }));

  const inferredVendorName = (bestCandidate.vendor as { vendor_name?: string } | null)?.vendor_name;

  return { items: correctedItems, inferredVendorName };
}

function normalizeItemText(value: string): string {
  return value
    .toLowerCase()
    .replace(/\s+/g, '')
    .replace(/[^a-z0-9ê°€-í£]/g, '')
    .trim();
}

function normalizeMappedNumber(value?: string): string {
  if (!value) return ''
  const cleaned = normalizeOrderCandidate(value)
  if (cleaned.startsWith('F')) return normalizePO(cleaned)
  if (cleaned.startsWith('HS')) return normalizeSO(cleaned)
  return cleaned
}

function normalizeOrderCandidate(value: string): string {
  const cleaned = value.toUpperCase().replace(/\s+/g, '').replace(/[^\w_-]/g, '')
  if (cleaned.startsWith('H5')) {
    return `HS${normalizeDigitConfusions(cleaned.slice(2))}`
  }
  if (cleaned.startsWith('HS')) {
    return `HS${normalizeDigitConfusions(cleaned.slice(2))}`
  }
  if (cleaned.startsWith('F')) {
    return `F${normalizeDigitConfusions(cleaned.slice(1))}`
  }
  return normalizeDigitConfusions(cleaned)
}

function normalizeDigitConfusions(value: string): string {
  const replacements: Record<string, string> = {
    O: '0',
    I: '1',
    L: '1',
    S: '5',
    B: '8',
    Z: '2'
  }
  return value
    .split('')
    .map((char) => replacements[char] ?? char)
    .join('')
}

function applyPoMappings(items: ExtractedItem[], mappings: PoMapping[]): ExtractedItem[] {
  if (!mappings.length) return items

  const byLine = new Map<number, PoMapping>()
  const byName = new Map<string, PoMapping>()
  const ranges: Array<{ start: number; end: number; po_number?: string; confidence?: number }> = []

  mappings.forEach((m) => {
    if (m.confidence !== undefined && m.confidence < 0.6) return
    if (typeof m.start_line === 'number' && typeof m.end_line === 'number') {
      if (m.start_line <= m.end_line) {
        ranges.push({ start: m.start_line, end: m.end_line, po_number: m.po_number, confidence: m.confidence })
      }
      return
    }
    if (typeof m.line_number === 'number') {
      byLine.set(m.line_number, m)
      return
    }
    if (m.item_name) {
      byName.set(normalizeItemText(m.item_name), m)
    }
  })

  return items.map((item, idx) => {
    const lineNumber = item.line_number ?? idx + 1
    const rangeMatches = ranges.filter(range => lineNumber >= range.start && lineNumber <= range.end)
    let rangeMatch: { po_number?: string; confidence?: number } | undefined = undefined
    if (rangeMatches.length > 0) {
      rangeMatch = rangeMatches
        .sort((a, b) => (b.confidence ?? 0) - (a.confidence ?? 0) || (a.end - a.start) - (b.end - b.start))[0]
    }
    const byLineMatch = byLine.get(lineNumber)
    const byNameMatch = byName.get(normalizeItemText(item.item_name || ''))
    const selected = rangeMatch || byLineMatch || byNameMatch
    const mapped = normalizeMappedNumber(selected?.po_number)
    if (!mapped) return item
    return { ...item, po_number: mapped }
  })
}

function buildInferredPoMap(params: {
  items: ExtractedItem[];
  visionWords: VisionWord[];
  bracketMappings: PoMapping[];
  rangeMappings: RangeMapping[];
}): Map<number, InferredPoInfo> {
  const { items, visionWords, bracketMappings, rangeMappings } = params
  const inferredMap = new Map<number, InferredPoInfo>()

  if (!items.length) return inferredMap

  const itemsWithLine = items.map((item, idx) => ({
    item,
    lineNumber: item.line_number || idx + 1
  }))

  const rows = visionWords.length > 0 ? groupWordsIntoRows(visionWords) : []
  const itemRowMap = rows.length > 0 ? mapItemsToRows(itemsWithLine, rows) : new Map<number, RowData>()
  const marginMap = rows.length > 0 ? mapMarginNumbersToItems(itemRowMap, rows) : new Map<number, InferredPoInfo>()
  const bracketMap = mapBracketMappingsToItems(itemsWithLine, bracketMappings)
  const rangeMap = mapRangeMappingsToItems(itemsWithLine, rangeMappings)
  const perItemMap = mapPerItemNumbers(itemsWithLine)
  const globalNumber = getGlobalPoNumber(items)

  itemsWithLine.forEach(({ lineNumber }) => {
    if (bracketMap.has(lineNumber)) {
      inferredMap.set(lineNumber, bracketMap.get(lineNumber)!)
      return
    }
    if (rangeMap.has(lineNumber)) {
      inferredMap.set(lineNumber, rangeMap.get(lineNumber)!)
      return
    }
    if (marginMap.has(lineNumber)) {
      inferredMap.set(lineNumber, marginMap.get(lineNumber)!)
      return
    }
    if (perItemMap.has(lineNumber)) {
      inferredMap.set(lineNumber, perItemMap.get(lineNumber)!)
      return
    }
    if (globalNumber) {
      inferredMap.set(lineNumber, {
        inferred_po_number: globalNumber,
        inferred_po_source: 'global',
        inferred_po_confidence: 0.55,
        inferred_po_group_id: `global-${globalNumber}`
      })
    }
  })

  return inferredMap
}

function groupWordsIntoRows(words: VisionWord[]): RowData[] {
  if (!words.length) return []

  const heights = words.map(word => word.bbox.h).filter(h => h > 0).sort((a, b) => a - b)
  const medianHeight = heights.length
    ? heights[Math.floor(heights.length / 2)]
    : 10
  const rowGap = Math.max(6, Math.round(medianHeight * 0.6))

  const sorted = [...words].sort((a, b) => (a.bbox.y + a.bbox.h / 2) - (b.bbox.y + b.bbox.h / 2))
  const rows: RowData[] = []

  sorted.forEach(word => {
    const centerY = word.bbox.y + word.bbox.h / 2
    const row = rows.find(r => Math.abs(r.centerY - centerY) <= rowGap)
    if (row) {
      row.words.push(word)
      row.centerY = (row.centerY * (row.words.length - 1) + centerY) / row.words.length
      row.minX = Math.min(row.minX, word.bbox.x)
      row.maxX = Math.max(row.maxX, word.bbox.x + word.bbox.w)
      row.minY = Math.min(row.minY, word.bbox.y)
      row.maxY = Math.max(row.maxY, word.bbox.y + word.bbox.h)
      return
    }

    rows.push({
      id: rows.length + 1,
      text: '',
      words: [word],
      minX: word.bbox.x,
      maxX: word.bbox.x + word.bbox.w,
      minY: word.bbox.y,
      maxY: word.bbox.y + word.bbox.h,
      centerY
    })
  })

  rows.forEach(row => {
    row.words.sort((a, b) => a.bbox.x - b.bbox.x)
    row.text = row.words.map(word => word.text).join(' ')
  })

  rows.sort((a, b) => a.centerY - b.centerY)
  return rows
}

function mapItemsToRows(
  itemsWithLine: Array<{ item: ExtractedItem; lineNumber: number }>,
  rows: RowData[]
): Map<number, RowData> {
  const rowMap = new Map<number, RowData>()

  itemsWithLine.forEach(({ item, lineNumber }, idx) => {
    const itemName = (item.item_name || '').trim()
    if (!itemName) return

    let bestRow: RowData | null = null
    let bestScore = 0

    rows.forEach(row => {
      const score = calculateRowMatchScore(itemName, row.text)
      if (score > bestScore) {
        bestScore = score
        bestRow = row
      }
    })

    if (bestRow && bestScore >= 35) {
      rowMap.set(lineNumber, bestRow)
      return
    }

    const fallbackRow = rows[idx]
    if (fallbackRow) {
      rowMap.set(lineNumber, fallbackRow)
    }
  })

  return rowMap
}

function mapMarginNumbersToItems(
  itemRowMap: Map<number, RowData>,
  rows: RowData[]
): Map<number, InferredPoInfo> {
  const inferredMap = new Map<number, InferredPoInfo>()
  if (!rows.length) return inferredMap

  const allMinX = rows.map(row => row.minX)
  const allMaxX = rows.map(row => row.maxX)
  const minX = Math.min(...allMinX)
  const maxX = Math.max(...allMaxX)
  const leftLimit = minX + (maxX - minX) * 0.2

  const marginNumbers = rows
    .map(row => {
      const leftWords = row.words.filter(word => word.bbox.x <= leftLimit + 2)
      const combinedText = leftWords.map(word => word.text).join(' ')
      const number = extractOrderNumber(combinedText)
      return number ? { number, centerY: row.centerY, rowId: row.id } : null
    })
    .filter((value): value is { number: string; centerY: number; rowId: number } => !!value)
    .sort((a, b) => a.centerY - b.centerY)

  if (!marginNumbers.length) return inferredMap

  itemRowMap.forEach((row, lineNumber) => {
    const match = marginNumbers
      .filter(candidate => candidate.centerY <= row.centerY)
      .slice(-1)[0]
    if (!match) return

    inferredMap.set(lineNumber, {
      inferred_po_number: match.number,
      inferred_po_source: 'margin_range',
      inferred_po_confidence: 0.7,
      inferred_po_group_id: `margin-${match.rowId}`
    })
  })

  return inferredMap
}

function mapBracketMappingsToItems(
  itemsWithLine: Array<{ item: ExtractedItem; lineNumber: number }>,
  mappings: PoMapping[]
): Map<number, InferredPoInfo> {
  const inferredMap = new Map<number, InferredPoInfo>()
  if (!mappings.length) return inferredMap

  const itemByLine = new Map<number, ExtractedItem>()
  itemsWithLine.forEach(({ item, lineNumber }) => {
    itemByLine.set(lineNumber, item)
  })

  mappings.forEach((mapping, index) => {
    const mappedNumber = normalizeMappedNumber(mapping.po_number)
    if (!mappedNumber) return
    const confidence = Math.max(0.5, Math.min(0.95, mapping.confidence ?? 0.8))

    if (typeof mapping.start_line === 'number' && typeof mapping.end_line === 'number') {
      const startLine = mapping.start_line
      const endLine = mapping.end_line
      if (startLine <= endLine) {
        const groupId = `bracket-range-${index + 1}-${mappedNumber}`
        itemsWithLine.forEach(({ lineNumber }) => {
          if (lineNumber >= startLine && lineNumber <= endLine && !inferredMap.has(lineNumber)) {
            inferredMap.set(lineNumber, {
              inferred_po_number: mappedNumber,
              inferred_po_source: 'bracket',
              inferred_po_confidence: confidence,
              inferred_po_group_id: groupId
            })
          }
        })
      }
      return
    }

    let lineNumber: number | undefined = undefined
    if (typeof mapping.line_number === 'number') {
      lineNumber = mapping.line_number
    } else if (mapping.item_name) {
      const bestMatch = findBestItemByName(itemsWithLine, mapping.item_name)
      lineNumber = bestMatch?.lineNumber
    }

    if (!lineNumber) return

    const groupId = `bracket-${mappedNumber}`
    inferredMap.set(lineNumber, {
      inferred_po_number: mappedNumber,
      inferred_po_source: 'bracket',
      inferred_po_confidence: confidence,
      inferred_po_group_id: groupId
    })

    const previousLine = lineNumber - 1
    const previousItem = itemByLine.get(previousLine)
    if (
      previousItem &&
      !inferredMap.has(previousLine) &&
      confidence >= 0.75 &&
      (previousItem.item_name || '').trim().length >= 2
    ) {
      inferredMap.set(previousLine, {
        inferred_po_number: mappedNumber,
        inferred_po_source: 'bracket',
        inferred_po_confidence: confidence,
        inferred_po_group_id: groupId
      })
    }
  })

  return inferredMap
}

function mapRangeMappingsToItems(
  itemsWithLine: Array<{ item: ExtractedItem; lineNumber: number }>,
  mappings: RangeMapping[]
): Map<number, InferredPoInfo> {
  const inferredMap = new Map<number, InferredPoInfo>()
  if (!mappings.length) return inferredMap

  mappings.forEach((mapping, index) => {
    const mappedNumber = normalizeMappedNumber(mapping.po_number)
    if (!mappedNumber) return
    const startLine = mapping.start_line
    const endLine = mapping.end_line
    if (!startLine || !endLine || startLine > endLine) return

    const confidence = Math.max(0.5, Math.min(0.95, mapping.confidence ?? 0.75))
    const groupId = `range-${index + 1}-${mappedNumber}`

    itemsWithLine.forEach(({ lineNumber }) => {
      if (lineNumber >= startLine && lineNumber <= endLine) {
        inferredMap.set(lineNumber, {
          inferred_po_number: mappedNumber,
          inferred_po_source: 'handwriting_range',
          inferred_po_confidence: confidence,
          inferred_po_group_id: groupId
        })
      }
    })
  })

  return inferredMap
}

function mapPerItemNumbers(
  itemsWithLine: Array<{ item: ExtractedItem; lineNumber: number }>
): Map<number, InferredPoInfo> {
  const inferredMap = new Map<number, InferredPoInfo>()

  itemsWithLine.forEach(({ item, lineNumber }) => {
    const number = normalizeMappedNumber(item.po_number)
    if (!number) return

    const confidence = item.confidence === 'high'
      ? 0.85
      : item.confidence === 'med'
        ? 0.7
        : 0.55

    inferredMap.set(lineNumber, {
      inferred_po_number: number,
      inferred_po_source: 'per_item',
      inferred_po_confidence: confidence
    })
  })

  return inferredMap
}

function getGlobalPoNumber(items: ExtractedItem[]): string | null {
  const uniqueNumbers = Array.from(new Set(
    items
      .map(item => normalizeMappedNumber(item.po_number))
      .filter((value): value is string => !!value)
  ))

  if (uniqueNumbers.length === 1) {
    return uniqueNumbers[0]
  }

  return null
}

function normalizeText(value: string): string {
  return value
    .toLowerCase()
    .replace(/\s+/g, '')
    .replace(/[^a-z0-9ê°€-í£]/g, '')
    .trim()
}

function calculateRowMatchScore(itemName: string, rowText: string): number {
  const normalizedItem = normalizeText(itemName)
  const normalizedRow = normalizeText(rowText)
  if (!normalizedItem || !normalizedRow) return 0

  if (normalizedRow.includes(normalizedItem) || normalizedItem.includes(normalizedRow)) {
    return 90
  }

  const itemTokens = tokenizeText(itemName)
  const rowTokens = tokenizeText(rowText)
  if (!itemTokens.length || !rowTokens.length) return 0

  const commonCount = itemTokens.filter(token => rowTokens.includes(token)).length
  const score = (commonCount / Math.max(itemTokens.length, rowTokens.length)) * 100
  return Math.round(score)
}

function tokenizeText(value: string): string[] {
  return value
    .toLowerCase()
    .split(/[^a-z0-9ê°€-í£]+/g)
    .map(token => token.trim())
    .filter(token => token.length >= 2)
}

function findBestItemByName(
  itemsWithLine: Array<{ item: ExtractedItem; lineNumber: number }>,
  query: string
): { lineNumber: number } | null {
  const normalizedQuery = normalizeText(query)
  if (!normalizedQuery) return null

  let bestLineNumber: number | null = null
  let bestScore = -1
  itemsWithLine.forEach(({ item, lineNumber }) => {
    const name = normalizeText(item.item_name || '')
    if (!name) return

    let score = 0
    if (name.includes(normalizedQuery) || normalizedQuery.includes(name)) {
      score = 90
    } else {
      const queryTokens = tokenizeText(query)
      const nameTokens = tokenizeText(item.item_name || '')
      const commonCount = queryTokens.filter(token => nameTokens.includes(token)).length
      score = (commonCount / Math.max(queryTokens.length, nameTokens.length || 1)) * 100
    }

    if (score > bestScore) {
      bestScore = score
      bestLineNumber = lineNumber
    }
  })

  if (!bestLineNumber || bestScore < 35) return null
  return { lineNumber: bestLineNumber }
}

function extractOrderNumber(text: string): string | null {
  if (!text) return null
  const cleaned = text.toUpperCase().replace(/\s+/g, '').replace(/[^\w_-]/g, '')

  const poMatch = cleaned.match(/F[0-9A-Z]{8}[_-][0-9A-Z]{1,3}/)
  if (poMatch) {
    const normalized = normalizeOrderCandidate(poMatch[0]).replace('-', '_')
    return normalizePO(normalized)
  }

  const soMatch = cleaned.match(/H[5S][0-9A-Z]{6}[-_][0-9A-Z]{1,2}/)
  if (soMatch) {
    const normalized = normalizeOrderCandidate(soMatch[0]).replace('_', '-')
    return normalizeSO(normalized)
  }

  return null
}

function calculateOrderSimilarity(
  ocrItems: Array<{ name: string; quantity: number }>,
  systemItems: Array<{ name: string; spec: string; quantity: number }>
): { score: number; matchedCount: number } {
  if (!ocrItems.length || !systemItems.length) {
    return { score: 0, matchedCount: 0 };
  }

  const usedSystem = new Set<number>();
  let totalScore = 0;
  let matchedCount = 0;

  for (const ocrItem of ocrItems) {
    let best = 0;
    let bestIndex = -1;

    for (let i = 0; i < systemItems.length; i += 1) {
      if (usedSystem.has(i)) continue;
      const sys = systemItems[i];
      const nameScore = calculateNameSimilarity(ocrItem.name, sys.name);
      const specScore = sys.spec ? calculateNameSimilarity(ocrItem.name, sys.spec) : 0;
      const baseScore = Math.max(nameScore, specScore);

      let quantityBonus = 0;
      if (ocrItem.quantity && sys.quantity) {
        if (ocrItem.quantity === sys.quantity) {
          quantityBonus = 20;
        } else if (ocrItem.quantity <= sys.quantity) {
          quantityBonus = 10;
        }
      }

      const total = baseScore + quantityBonus;
      if (total > best) {
        best = total;
        bestIndex = i;
      }
    }

    if (best >= 60 && bestIndex >= 0) {
      usedSystem.add(bestIndex);
      totalScore += best;
      matchedCount += 1;
    }
  }

  const matchRatio = matchedCount / ocrItems.length;
  const avgScore = matchedCount > 0 ? totalScore / matchedCount : 0;
  const score = Math.round((matchRatio * 50) + (avgScore * 0.5));

  return { score, matchedCount };
}

function calculateNameSimilarity(a: string, b: string): number {
  if (!a || !b) return 0;
  if (a === b) return 100;
  if (a.includes(b) || b.includes(a)) {
    const ratio = Math.min(a.length, b.length) / Math.max(a.length, b.length);
    return Math.round(80 + ratio * 20);
  }
  return 0;
}

